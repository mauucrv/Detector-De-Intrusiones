{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0227f69",
   "metadata": {},
   "source": [
    "# 00 - Ingesta y Optimización de Datos del CIC-IDS-2017\n",
    "\n",
    "**Objetivo:** Este notebook se encarga de leer los 8 archivos CSV originales del dataset, unirlos, realizar una limpieza inicial y guardarlos en un único archivo Parquet optimizado para su uso en análisis posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad00bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dccf71",
   "metadata": {},
   "source": [
    "## 1. Carga y Unión de Archivos CSV\n",
    "\n",
    "En esta sección, se localizan todos los archivos **.csv** dentro de la carpeta de datos crudos. Cada archivo se carga en un DataFrame de Pandas y luego se concatenan todos en un único DataFrame para facilitar su manejo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c22ef4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del dataframe completo: (2830743, 79)\n"
     ]
    }
   ],
   "source": [
    "# Cargar y unir los archivos CSV\n",
    "# Definir la ruta donde están los archivos CSV\n",
    "path_to_csvs = r'../data/raw/DatasetCICIDS2017/MachineLearningCVE/'  # Cambia esta ruta según la ubicación de tus archivos CSV\n",
    "\n",
    "# Se utiliza glob para encontrar todos los archivos CSV en el directorio\n",
    "csv_files = glob.glob(os.path.join(path_to_csvs, \"*.csv\")) # Lista de todos los archivos CSV en el directorio\n",
    "\n",
    "# Leer cada csv y guardarlo en una lista de dataframes\n",
    "df_list = [] # Lista para almacenar los dataframes\n",
    "for file_name in csv_files: # Iterar sobre cada archivo CSV\n",
    "    df = pd.read_csv(file_name) # Leer el archivo CSV\n",
    "    df_list.append(df) # Añadir el dataframe a la lista\n",
    "\n",
    "# Concatenar todos los dataframes en uno solo\n",
    "data = pd.concat(df_list, ignore_index = True) # Concatenar todos los dataframes en uno solo\n",
    "print(f\"Dimensiones del dataframe completo: {data.shape}\") # Imprimir las dimensiones del dataframe completo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587997b9",
   "metadata": {},
   "source": [
    "## 2. Limpieza Inicial\n",
    "\n",
    "Esta fase prepara el DataFrame para el análisis:\n",
    "1.  **Limpieza de Nombres:** Se eliminan los espacios en blanco de los nombres de las columnas.\n",
    "2.  **Manejo de Nulos:** Se reemplazan los valores infinitos (artefactos comunes en este dataset) por **NaN** y luego se eliminan las filas correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aa7bd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevas dimensiones del DataFrame: (2827876, 79)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limpieza y optimización inicial\n",
    "data.columns = data.columns.str.strip() # Eliminar espacios en los nombres de las columnas\n",
    "\n",
    "# El dataset CIC-IDS-2017 puede contener valores infinitos \n",
    "# Los reemplazamos con NaN (Not a Number) y luego eliminamos esas filas\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
    "data.dropna(inplace = True)\n",
    "print(f\"Nuevas dimensiones del DataFrame: {data.shape}\")\n",
    "data.isnull().sum().sum() # Verificar que no haya valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c61e0",
   "metadata": {},
   "source": [
    "## 3. Optimización Inicial y Guardado en Formato Parquet\n",
    "\n",
    "Finalmente, se aplica una función para reducir drásticamente el uso de memoria del DataFrame limpio, convirtiendo las columnas numéricas al tipo de dato más pequeño posible (**downcasting**) y las columnas de texto a un tipo **category** eficiente. El DataFrame optimizado se guarda en formato **Parquet**. Este formato es columnar, comprimido y mucho más rápido de leer que el CSV, lo que agilizará todos los análisis futuros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcba25ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memoria usada por el DataFrame: 1726.00 MB\n",
      "Memoria usada después de la optimización: 655.34 MB\n",
      "Reducción de memoria: 62.0%\n"
     ]
    }
   ],
   "source": [
    "# Función para reducir el uso de memoria del DataFrame\n",
    "def reduce_memory_usage(data):\n",
    "    start_mem = data.memory_usage().sum() / 1024**2 # Memoria inicial en MB\n",
    "    print(f\"Memoria usada por el DataFrame: {start_mem:.2f} MB\") \n",
    "\n",
    "    for col in data.columns: # Iterar sobre cada columna del DataFrame\n",
    "        col_type = data[col].dtype # Tipo de dato de la columna\n",
    "\n",
    "        if col_type != object and col_type.name != \"category\": # Si la columna no es de tipo object (cadena de texto)\n",
    "            c_min = data[col].min() # Valor mínimo de la columna\n",
    "            c_max = data[col].max() # Valor máximo de la columna\n",
    "\n",
    "            if str(col_type)[:3] == \"int\": # Si la columna es de tipo entero\n",
    "                if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max: # Verificar si cabe en int8\n",
    "                    data[col] = data[col].astype(np.int8) # Convertir a int8\n",
    "                elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max: # Verificar si cabe en int16\n",
    "                    data[col] = data[col].astype(np.int16) # Convertir a int16\n",
    "                elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max: # Verificar si cabe en int32\n",
    "                    data[col] = data[col].astype(np.int32) # Convertir a int32\n",
    "                elif c_min >= np.iinfo(np.int64).min and c_max <= np.iinfo(np.int64).max: # Verificar si cabe en int64\n",
    "                    data[col] = data[col].astype(np.int64) # Convertir a int64\n",
    "            else:\n",
    "                if c_min >= np.finfo(np.float16).min and c_max <= np.finfo(np.float16).max: # Verificar si cabe en float16\n",
    "                    data[col] = data[col].astype(np.float16) # Convertir a float16\n",
    "                elif c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max: # Verificar si cabe en float32\n",
    "                    data[col] = data[col].astype(np.float32) # Convertir a float32\n",
    "                else:\n",
    "                    data[col] = data[col].astype(np.float64) # Convertir a float64\n",
    "        else:\n",
    "            data[col] = data[col].astype(\"category\") # Convertir columnas de tipo object a category\n",
    "\n",
    "    end_mem = data.memory_usage().sum() / 1024**2 # Memoria final en MB\n",
    "    print(f\"Memoria usada después de la optimización: {end_mem:.2f} MB\") \n",
    "    print(f\"Reducción de memoria: {100 * (start_mem - end_mem) / start_mem:.1f}%\")\n",
    "    return data \n",
    "\n",
    "data = reduce_memory_usage(data) # Aplicar la función de reducción de memoria\n",
    "data.to_parquet(r\"../data/processed/cic_ids_2017_optimized.parquet\") # Guardar el DataFrame optimizado en formato Parquet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Cyber-Project)",
   "language": "python",
   "name": "cyber-project-py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
